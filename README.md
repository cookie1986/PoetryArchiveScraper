# PoetryArchiveScraper
A simple web scraper to access a poetry archive and store as plain text files.

## Installation



## Compliance with robots.txt
Before scraping the website, it's essential to check that the intended actions comply with the site's `robots.txt` file, which specifies the rules for web crawlers and scraping bots. Here are the steps taken to ensure compliance:

1. Located ```robots.txt``` file, found at ```hhttps://poetryarchive.org/robots.txt```.
2. Confirmed that all paths are allowed.
3. Checked for crawl delay information. No crawl delay was specified.
4. Located the XML sitemap for a list of URLs to be scraped.